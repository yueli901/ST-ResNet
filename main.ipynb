{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe3613c-6de5-4faa-84ee-2c25a6d06477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from st_resnet import ST_ResNet\n",
    "from params import Params as param\n",
    "from utils import batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f803a1d-6bce-4d0b-888a-de9ccb563938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate concatenated input for closeness, period and trend\n",
    "x_closeness = tf.random.normal(shape=(1000, param.map_height, param.map_width, param.closeness_sequence_length * param.nb_flow))\n",
    "x_period = tf.random.normal(shape=(1000, param.map_height, param.map_width, param.period_sequence_length * param.nb_flow))\n",
    "x_trend = tf.random.normal(shape=(1000, param.map_height, param.map_width, param.trend_sequence_length * param.nb_flow))\n",
    "y = tf.random.normal(shape=(1000, param.map_height, param.map_width, param.num_of_output))\n",
    "\n",
    "# concatenate the three inputs along the depth dimension\n",
    "X = tf.concat([x_closeness, x_period, x_trend], axis=-1)\n",
    "\n",
    "# create train-test split of data\n",
    "train_index = int(round((0.8*len(X)),0))\n",
    "xtrain = X[:train_index]\n",
    "ytrain = y[:train_index]\n",
    "xtest = X[train_index:]\n",
    "ytest = y[train_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb77a5b-ec07-4eef-8f4c-a7d3cc327755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain an interator for the next batch\n",
    "train_batch_generator = batch_generator(xtrain, ytrain, param.batch_size)\n",
    "test_batch_generator = batch_generator(xtest, ytest, param.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a76fe26-aecc-4989-a57b-0f5f8f14109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ST_ResNet()\n",
    "\n",
    "closeness_shape = (1, 32, 32, param.closeness_sequence_length * param.nb_flow)\n",
    "period_shape = (1, 32, 32, param.period_sequence_length * param.nb_flow)\n",
    "trend_shape = (1, 32, 32, param.trend_sequence_length * param.nb_flow)\n",
    "\n",
    "dummy_closeness = tf.random.normal(closeness_shape)\n",
    "dummy_period = tf.random.normal(period_shape)\n",
    "dummy_trend = tf.random.normal(trend_shape)\n",
    "\n",
    "dummy_output = g(dummy_closeness, dummy_period, dummy_trend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d717063-d385-42b0-8e20-335040164e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\t\n",
      "loss: 2.309, val_loss: 1.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_fn, conv2d_156_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_181_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses while saving (showing 5 of 450). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_logs/20230326-221051/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_logs/20230326-221051/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t\n",
      "loss: 1.006, val_loss: 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_fn, conv2d_156_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_181_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses while saving (showing 5 of 450). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_logs/20230326-221051/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_logs/20230326-221051/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\t\n",
      "loss: 1.004, val_loss: 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_156_layer_call_fn, conv2d_156_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_181_layer_call_fn, conv2d_181_layer_call_and_return_conditional_losses while saving (showing 5 of 450). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_logs/20230326-221051/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_logs/20230326-221051/assets\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(param.num_epochs):\n",
    "    loss_train = 0\n",
    "    loss_val = 0\n",
    "    print(\"Epoch: {}\\t\".format(epoch), )\n",
    "    \n",
    "    # Training\n",
    "    num_batches = xtrain.shape[0] // param.batch_size\n",
    "    for b in range(num_batches):\n",
    "        x_batch, y_batch = next(train_batch_generator)\n",
    "        x_closeness = x_batch[:, :, :, :param.closeness_sequence_length * param.nb_flow]\n",
    "        x_period = x_batch[:, :, :, param.closeness_sequence_length * param.nb_flow:param.closeness_sequence_length * param.nb_flow + param.period_sequence_length * param.nb_flow]\n",
    "        x_trend = x_batch[:, :, :, param.closeness_sequence_length * param.nb_flow + param.period_sequence_length * param.nb_flow:]\n",
    "        result = g.train_step(((x_closeness, x_period, x_trend), y_batch))\n",
    "        loss_tr = result['loss_train']\n",
    "        loss_train = loss_tr * param.delta + loss_train * (1 - param.delta) # exponential moving average (EMA) update rule for the training loss\n",
    "    \n",
    "        with tf.summary.create_file_writer(param.log_dir + '/train').as_default():\n",
    "            tf.summary.scalar('loss', loss_tr, step=epoch * num_batches + b)\n",
    "    \n",
    "    # Testing\n",
    "    num_batches = xtest.shape[0] // param.batch_size\n",
    "    for b in range(num_batches):\n",
    "        x_batch, y_batch = next(test_batch_generator)\n",
    "        x_closeness = x_batch[:, :, :, :param.closeness_sequence_length * param.nb_flow]\n",
    "        x_period = x_batch[:, :, :, param.closeness_sequence_length * param.nb_flow:param.closeness_sequence_length * param.nb_flow + param.period_sequence_length * param.nb_flow]\n",
    "        x_trend = x_batch[:, :, :, param.closeness_sequence_length * param.nb_flow + param.period_sequence_length * param.nb_flow:]\n",
    "        result = g.test_step(((x_closeness, x_period, x_trend), y_batch))\n",
    "        loss_v = result['loss_test']\n",
    "        loss_val += loss_v\n",
    "        \n",
    "        with tf.summary.create_file_writer(param.log_dir + '/val').as_default():\n",
    "            tf.summary.scalar('loss', loss_v, step=epoch * num_batches + b)\n",
    "    \n",
    "    if(num_batches != 0):\n",
    "        loss_val /= num_batches\n",
    "    \n",
    "    print(\"loss: {:.3f}, val_loss: {:.3f}\".format(loss_train, loss_val))\n",
    "    \n",
    "    # Save the model after every epoch\n",
    "    g.save(param.model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544862f2-9338-4eb4-991d-8d651b5e946b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Environment",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
